{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b368ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from typing import Any, Dict, List, Tuple\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eecf3f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder with the ground-truth texts\n",
    "ANNOTATIONS_FOLDER = \"../annotations/\"\n",
    "\n",
    "# List of entities to tag (by the llms) and then extract\n",
    "TAGS = [\"MOL\", \"SOFTNAME\", \"SOFTVERS\", \"STIME\", \"TEMP\", \"FFM\"]\n",
    "\n",
    "# Change this path to the results we want to score\n",
    "QC_RESULTS_PATH = \"../llm_outputs/stats_2025-04-28_15-06-21/quality_control_results.csv\"\n",
    "\n",
    "# Path to the where we will be writing the scoring results\n",
    "SCORE_RESULTS_PATH = \"../llm_outputs/stats_2025-04-28_15-06-21/scoring_results.csv\"\n",
    "SCORE_RESULTS_FOLDER = \"../llm_outputs/stats_2025-04-28_15-06-21/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e240d5",
   "metadata": {},
   "source": [
    "## **LLM annotations scoring**\n",
    "---\n",
    "\n",
    "To assess the quality of entity annotations produced by different LLMs, we implement a set of evaluation metrics that allow both quantitative and qualitative analysis. We aim to measure how well each model performs in identifying and labeling entities.\n",
    "\n",
    "However, before we can properly assess the quality of the annotations, we need to extarct the entities and store them in a standard structure.\n",
    "Both the ground-truth entities and the llm-annotated entities will be in the following structure:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"MOL\": [\"arylamide\", \"hDM2\", \"p53\", \"Nutlin-2\", \"benzodiazepinedione\"],\n",
    "  \"SOFTNAME\": [\"AutoDock\"],\n",
    "  \"SOFTVERS\": [],\n",
    "  \"STIME\": [\"20 ns\"],\n",
    "  \"TEMP\": [],\n",
    "  \"FFM\": [\"GAFF\"]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808d295e",
   "metadata": {},
   "source": [
    "For this, we need different helper functions that will: :\n",
    "\n",
    "- convert the current **ground-truth annotation** format to the one we want\n",
    "\n",
    "\n",
    "Current ground-truth annotation format:\n",
    "```json\n",
    "{\n",
    "  \"classes\": [\"TEMP\", \"SOFT\", \"STIME\", \"MOL\", \"FFM\"],\n",
    "  \"annotations\": [[\n",
    "      \"An in silico approach to determine inter-subunit affinities in human septin complexes.\",\n",
    "      {\"entities\": [[69, 75, \"MOL\"], [90, 97, \"MOL\"], [1255, 1260, \"MOL\"], [1368, 1374, \"MOL\"]]}\n",
    "  ]]\n",
    "}\n",
    "```\n",
    "\n",
    "- convert the **llm-ouput annotation** format to the one we want\n",
    "\n",
    "llm-ouput annotation format:\n",
    "```json\n",
    "{\n",
    "  \"model\": \"gemma2-9b-it\",\n",
    "  \"text_to_annotate\": \"Extending the Stochastic Titration CpHMD to CHARMM36m.\",\n",
    "  \"response\": \"Extending the Stochastic Titration CpHMD to <FFM>CHARMM36m</FFM>.\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d419ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract entities from ground truth\n",
    "def extract_entities_from_annotation(text: str, entities: list) -> dict:\n",
    "    \"\"\"\n",
    "    Extract entities from the given text based on a direct list of annotation triples.\n",
    "\n",
    "    The entities input should be a list of lists formatted as:\n",
    "    [\n",
    "        [start_index, end_index, \"ENTITY_TYPE\"],\n",
    "        ...\n",
    "    ]\n",
    "    \n",
    "    The function extracts the substring from the text using the provided character indices\n",
    "    and groups the results by the entity type according to TAGS.\n",
    "    If an entity type is not in TAGS, it will be ignored.\n",
    "    If no entities are found for a type, its output list will remain empty.\n",
    "    \n",
    "    The function returns a dictionary with keys corresponding to the desired entity types\n",
    "    and values as lists with the extracted entity content.\n",
    "    \"\"\"\n",
    "    # Initialize the output dictionary with empty lists for each desired key.\n",
    "    result = {key: [] for key in TAGS}\n",
    "    \n",
    "    # Iterate over each entity annotation.\n",
    "    for start, end, entity_type in entities:\n",
    "        if entity_type == 'SOFT':\n",
    "            entity_type = 'SOFTNAME'\n",
    "\n",
    "        extracted = text[start:end]\n",
    "        result[entity_type].append(extracted)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Extract entities from the LLM output text\n",
    "def extract_entities_from_llm_text(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract entities from an output text based on tagged annotations.\n",
    "    \n",
    "    The input text is expected to have entities enclosed in tags, e.g.:\n",
    "    \"Extending the Stochastic Titration CpHMD to <FFM>CHARMM36m</FFM> using <SOFTNAME>Gromacs</SOFTNAME>\"\n",
    "    \n",
    "    The function returns a dictionary with keys corresponding to the desired entity types\n",
    "    and values as lists with the extracted entity content.\n",
    "    \"\"\"\n",
    "    # Initialize the results with empty lists for all desired keys.\n",
    "    result = {key: [] for key in TAGS}\n",
    "    \n",
    "    # Use a regex to capture tags in the format <TAG>content</TAG>\n",
    "    # The regex uses a backreference to ensure matching closing tag.\n",
    "    pattern = re.compile(r\"<([A-Z]+)>(.*?)</\\1>\")\n",
    "    \n",
    "    # Find all matches in the text.\n",
    "    for tag, content in pattern.findall(text):\n",
    "        # If the tag is one of our desired keys, append the content (stripped of whitespace)\n",
    "        if tag in result:\n",
    "            result[tag].append(content.strip())\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa875e78",
   "metadata": {},
   "source": [
    "Now onto the scoring. **Evaluation logic:**\n",
    "\n",
    "\n",
    "\n",
    "1. **Exact match scoring**: Entity is correct if string and type match exactly.\n",
    "\n",
    "\n",
    "2. **Confidence score**: Fraction of LLMs that agreed on the same entity. (!!! tricky because not all the llms will conserve the text) - ***Not added in yet***\n",
    "\n",
    "\n",
    "3. **Detection ratio**: Correct entities found vs. total ground truth.\n",
    "\n",
    "\n",
    "4. **False positives**: Entities predicted but not in ground truth.\n",
    "\n",
    "\n",
    "5. **False negatives**: Ground truth entities missed by LLM.\n",
    "\n",
    "\n",
    "6. **Per-type breakdown**: Scores computed by entity type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "08810902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the exact match score\n",
    "def exact_match_score(ground_truth: Dict[str, List[str]], predicted: Dict[str, List[str]]) -> Tuple[int, int, float]:\n",
    "    \"\"\"\n",
    "    Computes the exact match score across all types.\n",
    "    \n",
    "    - An entity is an exact match if both its string and type match.\n",
    "    - Returns a tuple of (matched_count, total_ground_truth_count, ratio).\n",
    "    \n",
    "    Parameters:\n",
    "        ground_truth (dict): Ground truth annotations.\n",
    "        predicted (dict): Predicted annotations.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (number of exact matches, total ground truth entities, score ratio)\n",
    "    \"\"\"\n",
    "    matched = 0\n",
    "    total = 0\n",
    "    # print(ground_truth.items())\n",
    "    for entity_type, gt_entities in ground_truth.items():\n",
    "        \n",
    "        total += len(gt_entities)\n",
    "        pred_entities = set(predicted.get(entity_type, []))\n",
    "        \n",
    "        # Count only those ground truth entities that appear exactly in the predictions.\n",
    "        for entity in gt_entities:\n",
    "            if entity in pred_entities:\n",
    "                matched += 1\n",
    "                \n",
    "    score_ratio = matched / total if total > 0 else 0\n",
    "    return matched, total, score_ratio\n",
    "\n",
    "\n",
    "def detection_ratio(ground_truth: Dict[str, List[str]], predicted: Dict[str, List[str]]) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Computes the detection ratio per entity type.\n",
    "    \n",
    "    - For each entity type, computes the fraction of ground truth entities that were found in the predicted entities.\n",
    "    \n",
    "    Parameters:\n",
    "        ground_truth (dict): Ground truth annotations.\n",
    "        predicted (dict): Predicted annotations.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Mapping from entity type to detection ratio (0 to 1).\n",
    "    \"\"\"\n",
    "    ratios = {}\n",
    "    for entity_type, gt_entities in ground_truth.items():\n",
    "        pred_entities = set(predicted.get(entity_type, []))\n",
    "        if gt_entities:\n",
    "            detected = sum(1 for entity in gt_entities if entity in pred_entities)\n",
    "            ratios[entity_type] = detected / len(gt_entities)\n",
    "        else:\n",
    "            ratios[entity_type] = None  # Undefined (or could be set to 0) if no ground truth for the type.\n",
    "    return ratios\n",
    "\n",
    "\n",
    "def false_positives(ground_truth: Dict[str, List[str]], predicted: Dict[str, List[str]]) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Computes false positive entities per entiy type.\n",
    "    \n",
    "    - False positive: An entity predicted that is not present in the corresponding ground truth.\n",
    "    \n",
    "    Parameters:\n",
    "        ground_truth (dict): Ground truth annotations.\n",
    "        predicted (dict): Predicted annotations.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Mapping from entity type to a list of false positive entities.\n",
    "    \"\"\"\n",
    "    false_positives = {}\n",
    "    for entity_type, pred_entities in predicted.items():\n",
    "        gt_entities = set(ground_truth.get(entity_type, []))\n",
    "        # Any predicted entity not in ground truth is a false positive.\n",
    "        false_positives[entity_type] = [entity for entity in pred_entities if entity not in gt_entities]\n",
    "    return false_positives\n",
    "\n",
    "\n",
    "def false_negatives(ground_truth: Dict[str, List[str]], predicted: Dict[str, List[str]]) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Computes false negative entities per entity type.\n",
    "    \n",
    "    - False negative: A ground truth entity that was missed by prediction.\n",
    "    \n",
    "    Parameters:\n",
    "        ground_truth (dict): Ground truth annotations.\n",
    "        predicted (dict): Predicted annotations.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Mapping from entity type to a list of false negative entities.\n",
    "    \"\"\"\n",
    "    false_negatives = {}\n",
    "    for entity_type, gt_entities in ground_truth.items():\n",
    "        pred_entities = set(predicted.get(entity_type, []))\n",
    "        # Any ground truth entity not found in predictions is a false negative.\n",
    "        false_negatives[entity_type] = [entity for entity in gt_entities if entity not in pred_entities]\n",
    "    return false_negatives\n",
    "\n",
    "\n",
    "def per_type_breakdown(ground_truth: Dict[str, List[str]], predicted: Dict[str, List[str]]) -> Dict[str, Dict[str, any]]:\n",
    "    \"\"\"\n",
    "    Provides a detailed breakdown per entity type.\n",
    "    \n",
    "    For each entity type, returns a dict with:\n",
    "      - 'exact_matches': number of exact matches,\n",
    "      - 'total_gt': total number of ground truth entities,\n",
    "      - 'detection_ratio': fraction of ground truth detected,\n",
    "      - 'false_positives': list of false positive entities,\n",
    "      - 'false_negatives': list of false negative entities.\n",
    "    \n",
    "    Parameters:\n",
    "        ground_truth (dict): Ground truth annotations.\n",
    "        predicted (dict): Predicted annotations.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Breakdown per entity type.\n",
    "    \"\"\"\n",
    "    breakdown = {}\n",
    "    for entity_type in set(ground_truth.keys()).union(set(predicted.keys())):\n",
    "        gt_entities = ground_truth.get(entity_type, [])\n",
    "        pred_entities = predicted.get(entity_type, [])\n",
    "        gt_set = set(gt_entities)\n",
    "        pred_set = set(pred_entities)\n",
    "        \n",
    "        exact_match_count = sum(1 for e in gt_entities if e in pred_set)\n",
    "        total_gt = len(gt_entities)\n",
    "        detection = exact_match_count / total_gt if total_gt > 0 else None\n",
    "        \n",
    "        breakdown[entity_type] = {\n",
    "            'exact_matches': exact_match_count,\n",
    "            'total_gt': total_gt,\n",
    "            'detection_ratio': detection,\n",
    "            'false_positives': len([e for e in pred_entities if e not in gt_set]),\n",
    "            'false_negatives': len([e for e in gt_entities if e not in pred_set])\n",
    "        }\n",
    "        \n",
    "    return breakdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e5e075",
   "metadata": {},
   "source": [
    "Now, we go looking for the texts to score.\n",
    "\n",
    "We can extract them from a quality control (QC) summary (csv file). We just need to specify the file we are interested in, in order to then extract the texts that are worth scoring (those that have at least one entity that we know exists in the original text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d35948d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_annotations_to_score(\n",
    "    csv_file: str | Path,\n",
    ") -> Tuple[pd.DataFrame, List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Return the subset of rows with ``one_entity_verified == True`` and\n",
    "    give back the two key columns as Python lists.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_file : str | Path\n",
    "        Path to *filtering_results.csv*.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (filtered_df,\n",
    "         filenames,            # list[str]\n",
    "         full_paths)           # list[str]\n",
    "    \"\"\"\n",
    "    csv_file = Path(csv_file)\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    filtered = df[df[\"one_entity_verified\"]]\n",
    "\n",
    "    filenames  = filtered[\"filename\"].tolist()\n",
    "    full_paths = filtered[\"full_path\"].tolist()\n",
    "\n",
    "    return filtered[[\"prompt\", \"model\", \"filename\", \"full_path\"]], filenames, full_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c17c3685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      prompt                                          model  \\\n",
      "0  zero_shot  meta-llama/llama-4-maverick-17b-128e-instruct   \n",
      "1  zero_shot  meta-llama/llama-4-maverick-17b-128e-instruct   \n",
      "2  zero_shot  meta-llama/llama-4-maverick-17b-128e-instruct   \n",
      "3  zero_shot  meta-llama/llama-4-maverick-17b-128e-instruct   \n",
      "4  zero_shot  meta-llama/llama-4-maverick-17b-128e-instruct   \n",
      "\n",
      "                 filename                                          full_path  \n",
      "0  figshare_22213635.json  ../llm_outputs/annotations_2025-04-28_15-06-21...  \n",
      "1   figshare_4757161.json  ../llm_outputs/annotations_2025-04-28_15-06-21...  \n",
      "2  figshare_21263177.json  ../llm_outputs/annotations_2025-04-28_15-06-21...  \n",
      "3     zenodo_6582985.json  ../llm_outputs/annotations_2025-04-28_15-06-21...  \n",
      "4     zenodo_6478270.json  ../llm_outputs/annotations_2025-04-28_15-06-21...  \n"
     ]
    }
   ],
   "source": [
    "# Load the filtered results from the QC results summary\n",
    "# and extract the filenames and full paths to the annotations\n",
    "df, filenames, llm_filenames = extract_annotations_to_score(QC_RESULTS_PATH)\n",
    "\n",
    "# View the first 5 rows\n",
    "print(df.head())\n",
    "\n",
    "# print(df.iloc[0, 0])  # Prompt\n",
    "# print(df.iloc[0, 1])  # Model\n",
    "\n",
    "# print(len(filenames)) # Names of the orginal files\n",
    "# print(len(llm_filenames)) # Full paths to the annotated llm files\n",
    "\n",
    "# Change filenames to the full path of the orignal ground truths\n",
    "for i in range(len(filenames)):\n",
    "    filenames[i] = os.path.join(ANNOTATIONS_FOLDER, filenames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3a22399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process one JSON file to extract the ground truth entities and the input text\n",
    "def process_json_file(json_file: str) -> tuple:\n",
    "    with open(json_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract the input text\n",
    "    annotation_entry = data[\"annotations\"][0]\n",
    "    input_text = annotation_entry[0]\n",
    "    ground_truth_entities = annotation_entry[1][\"entities\"]\n",
    "\n",
    "    return input_text, ground_truth_entities\n",
    "\n",
    "# Process one LLM JSON file to extract the input text, response, and model\n",
    "def process_llm_json_file(json_file: str) -> tuple:\n",
    "    with open(json_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract the input text, response, and model\n",
    "    text_to_annotate = data[\"text_to_annotate\"]\n",
    "    response = data[\"response\"]\n",
    "    model = data[\"model\"]\n",
    "\n",
    "    return text_to_annotate, response, model\n",
    "\n",
    "# Saves the scoring results to a CSV file one row at a time\n",
    "def save_scoring_results_to_csv(rows: List[Dict[str, Any]], output_dir: str | Path) -> None:\n",
    "    \"\"\"Append rows to filtering_results.csv inside output_dir.\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    csv_path = output_dir / \"scoring_results.csv\" # Name of the CSV file\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(csv_path, index=False, mode=\"a\", header=not csv_path.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13611aa2",
   "metadata": {},
   "source": [
    "### **Actual scoring and saving results:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a14d4f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file: ../llm_outputs/stats_2025-04-28_15-06-21/scoring_results.csv\n",
      "\n",
      "\n",
      "../llm_outputs/annotations_2025-04-28_15-06-21/zero_shot/meta-llama/llama-4-maverick-17b-128e-instruct/figshare_22213635.json \n",
      "\n",
      "★ Exact match score: 9/10 (0.90)\n",
      "\n",
      "★ False positives (hallucination ?):\n",
      "  MOL: ['ammonia', 'NH3+ H2']\n",
      "  SOFTNAME: ['MP2', 'cc-pVDZ', 'CCSD (T)', 'cc-pVTZ']\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: ['T130 K']\n",
      "  FFM: []\n",
      "\n",
      "★ False negatives (missed ?):\n",
      "  MOL: []\n",
      "  SOFTNAME: []\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: ['130 K']\n",
      "  FFM: []\n",
      "\n",
      "★ Detection ratio per type (# of correct entities found by LLM ÷ # of entities in the ground truth):\n",
      "  MOL: 1.0\n",
      "  SOFTNAME: None\n",
      "  SOFTVERS: None\n",
      "  STIME: None\n",
      "  TEMP: 0.0\n",
      "  FFM: None\n",
      "\n",
      "★ Per-type breakdown:\n",
      "  TEMP: {'exact_matches': 0, 'total_gt': 1, 'detection_ratio': 0.0, 'false_positives': 1, 'false_negatives': 1}\n",
      "  MOL: {'exact_matches': 9, 'total_gt': 9, 'detection_ratio': 1.0, 'false_positives': 2, 'false_negatives': 0}\n",
      "  FFM: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  SOFTNAME: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 4, 'false_negatives': 0}\n",
      "  STIME: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  SOFTVERS: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "\n",
      "../llm_outputs/annotations_2025-04-28_15-06-21/zero_shot/meta-llama/llama-4-maverick-17b-128e-instruct/figshare_4757161.json \n",
      "\n",
      "★ Exact match score: 36/50 (0.72)\n",
      "\n",
      "★ False positives (hallucination ?):\n",
      "  MOL: ['catalyst', 'hydrophobic residue', 'polystyrene', 'HST', 'TST', 'SCL', 'SDB', 'catalyst', 'hydrophobic residue', 'catalyst', 'hydrophobic residue', 'TIP3P', 'catalyst', 'hydrophobic residues']\n",
      "  SOFTNAME: ['prepgen', 'Langevin thermostat', 'cpptraj']\n",
      "  SOFTVERS: []\n",
      "  STIME: ['2.1 ns']\n",
      "  TEMP: []\n",
      "  FFM: ['General Amber Force Field (GAFF)']\n",
      "\n",
      "★ False negatives (missed ?):\n",
      "  MOL: ['Enzyme', 'Polystyrene', 'methyl', '2-phenylpropane', 'methyl', 'methyl', 'methyl', 'methyl', 'alkyl', 'p-divinylbenzene', 'p-divinylbenzene', 'waters']\n",
      "  SOFTNAME: []\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: []\n",
      "  FFM: ['General Amber Force Field', 'TIP3P']\n",
      "\n",
      "★ Detection ratio per type (# of correct entities found by LLM ÷ # of entities in the ground truth):\n",
      "  MOL: 0.6129032258064516\n",
      "  SOFTNAME: 1.0\n",
      "  SOFTVERS: None\n",
      "  STIME: 1.0\n",
      "  TEMP: 1.0\n",
      "  FFM: 0.5\n",
      "\n",
      "★ Per-type breakdown:\n",
      "  TEMP: {'exact_matches': 4, 'total_gt': 4, 'detection_ratio': 1.0, 'false_positives': 0, 'false_negatives': 0}\n",
      "  MOL: {'exact_matches': 19, 'total_gt': 31, 'detection_ratio': 0.6129032258064516, 'false_positives': 14, 'false_negatives': 12}\n",
      "  FFM: {'exact_matches': 2, 'total_gt': 4, 'detection_ratio': 0.5, 'false_positives': 1, 'false_negatives': 2}\n",
      "  SOFTNAME: {'exact_matches': 10, 'total_gt': 10, 'detection_ratio': 1.0, 'false_positives': 3, 'false_negatives': 0}\n",
      "  STIME: {'exact_matches': 1, 'total_gt': 1, 'detection_ratio': 1.0, 'false_positives': 1, 'false_negatives': 0}\n",
      "  SOFTVERS: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "\n",
      "../llm_outputs/annotations_2025-04-28_15-06-21/zero_shot/meta-llama/llama-4-maverick-17b-128e-instruct/figshare_21263177.json \n",
      "\n",
      "★ Exact match score: 8/11 (0.73)\n",
      "\n",
      "★ False positives (hallucination ?):\n",
      "  MOL: ['proteins', 'proteins', 'E. coli thioredoxins', 'proteins', 'thioredoxin', 'proteins', 'membrane proteins', 'lipid bilayers', 'nucleic acids']\n",
      "  SOFTNAME: []\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: []\n",
      "  FFM: ['GROMOS54A7']\n",
      "\n",
      "★ False negatives (missed ?):\n",
      "  MOL: ['human and E. coli thioredoxins', 'human thioredoxin']\n",
      "  SOFTNAME: []\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: []\n",
      "  FFM: ['GROMOS 54A7']\n",
      "\n",
      "★ Detection ratio per type (# of correct entities found by LLM ÷ # of entities in the ground truth):\n",
      "  MOL: 0.6\n",
      "  SOFTNAME: 1.0\n",
      "  SOFTVERS: None\n",
      "  STIME: None\n",
      "  TEMP: None\n",
      "  FFM: 0.8\n",
      "\n",
      "★ Per-type breakdown:\n",
      "  TEMP: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  MOL: {'exact_matches': 3, 'total_gt': 5, 'detection_ratio': 0.6, 'false_positives': 9, 'false_negatives': 2}\n",
      "  FFM: {'exact_matches': 4, 'total_gt': 5, 'detection_ratio': 0.8, 'false_positives': 1, 'false_negatives': 1}\n",
      "  SOFTNAME: {'exact_matches': 1, 'total_gt': 1, 'detection_ratio': 1.0, 'false_positives': 0, 'false_negatives': 0}\n",
      "  STIME: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  SOFTVERS: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "\n",
      "../llm_outputs/annotations_2025-04-28_15-06-21/zero_shot/meta-llama/llama-4-maverick-17b-128e-instruct/zenodo_6582985.json \n",
      "\n",
      "★ Exact match score: 10/13 (0.77)\n",
      "\n",
      "★ False positives (hallucination ?):\n",
      "  MOL: ['lipids']\n",
      "  SOFTNAME: ['Desmond']\n",
      "  SOFTVERS: ['2019-4']\n",
      "  STIME: ['0-500ns']\n",
      "  TEMP: []\n",
      "  FFM: []\n",
      "\n",
      "★ False negatives (missed ?):\n",
      "  MOL: []\n",
      "  SOFTNAME: ['Desmond 2019-4', 'desmond', 'desmond']\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: []\n",
      "  FFM: []\n",
      "\n",
      "★ Detection ratio per type (# of correct entities found by LLM ÷ # of entities in the ground truth):\n",
      "  MOL: 1.0\n",
      "  SOFTNAME: 0.25\n",
      "  SOFTVERS: None\n",
      "  STIME: 1.0\n",
      "  TEMP: None\n",
      "  FFM: 1.0\n",
      "\n",
      "★ Per-type breakdown:\n",
      "  TEMP: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  MOL: {'exact_matches': 6, 'total_gt': 6, 'detection_ratio': 1.0, 'false_positives': 1, 'false_negatives': 0}\n",
      "  FFM: {'exact_matches': 2, 'total_gt': 2, 'detection_ratio': 1.0, 'false_positives': 0, 'false_negatives': 0}\n",
      "  SOFTNAME: {'exact_matches': 1, 'total_gt': 4, 'detection_ratio': 0.25, 'false_positives': 1, 'false_negatives': 3}\n",
      "  STIME: {'exact_matches': 1, 'total_gt': 1, 'detection_ratio': 1.0, 'false_positives': 1, 'false_negatives': 0}\n",
      "  SOFTVERS: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 1, 'false_negatives': 0}\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "\n",
      "../llm_outputs/annotations_2025-04-28_15-06-21/zero_shot/meta-llama/llama-4-maverick-17b-128e-instruct/zenodo_6478270.json \n",
      "\n",
      "★ Exact match score: 3/9 (0.33)\n",
      "\n",
      "★ False positives (hallucination ?):\n",
      "  MOL: ['LNX2 protein', '4 symmetrically related protein chains']\n",
      "  SOFTNAME: []\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: []\n",
      "  FFM: ['CHARMM-modified TIP3P']\n",
      "\n",
      "★ False negatives (missed ?):\n",
      "  MOL: ['LNX2', 'Water', 'water', 'water']\n",
      "  SOFTNAME: []\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: []\n",
      "  FFM: ['CHARMM', 'TIP3P']\n",
      "\n",
      "★ Detection ratio per type (# of correct entities found by LLM ÷ # of entities in the ground truth):\n",
      "  MOL: 0.2\n",
      "  SOFTNAME: None\n",
      "  SOFTVERS: None\n",
      "  STIME: 1.0\n",
      "  TEMP: None\n",
      "  FFM: 0.3333333333333333\n",
      "\n",
      "★ Per-type breakdown:\n",
      "  TEMP: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  MOL: {'exact_matches': 1, 'total_gt': 5, 'detection_ratio': 0.2, 'false_positives': 2, 'false_negatives': 4}\n",
      "  FFM: {'exact_matches': 1, 'total_gt': 3, 'detection_ratio': 0.3333333333333333, 'false_positives': 1, 'false_negatives': 2}\n",
      "  SOFTNAME: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  STIME: {'exact_matches': 1, 'total_gt': 1, 'detection_ratio': 1.0, 'false_positives': 0, 'false_negatives': 0}\n",
      "  SOFTVERS: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "\n",
      "../llm_outputs/annotations_2025-04-28_15-06-21/one_shot/meta-llama/llama-4-maverick-17b-128e-instruct/figshare_22213635.json \n",
      "\n",
      "★ Exact match score: 9/10 (0.90)\n",
      "\n",
      "★ False positives (hallucination ?):\n",
      "  MOL: []\n",
      "  SOFTNAME: []\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: ['T130 K']\n",
      "  FFM: []\n",
      "\n",
      "★ False negatives (missed ?):\n",
      "  MOL: []\n",
      "  SOFTNAME: []\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: ['130 K']\n",
      "  FFM: []\n",
      "\n",
      "★ Detection ratio per type (# of correct entities found by LLM ÷ # of entities in the ground truth):\n",
      "  MOL: 1.0\n",
      "  SOFTNAME: None\n",
      "  SOFTVERS: None\n",
      "  STIME: None\n",
      "  TEMP: 0.0\n",
      "  FFM: None\n",
      "\n",
      "★ Per-type breakdown:\n",
      "  TEMP: {'exact_matches': 0, 'total_gt': 1, 'detection_ratio': 0.0, 'false_positives': 1, 'false_negatives': 1}\n",
      "  MOL: {'exact_matches': 9, 'total_gt': 9, 'detection_ratio': 1.0, 'false_positives': 0, 'false_negatives': 0}\n",
      "  FFM: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  SOFTNAME: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  STIME: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  SOFTVERS: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "\n",
      "../llm_outputs/annotations_2025-04-28_15-06-21/one_shot/meta-llama/llama-4-maverick-17b-128e-instruct/figshare_4757161.json \n",
      "\n",
      "★ Exact match score: 32/50 (0.64)\n",
      "\n",
      "★ False positives (hallucination ?):\n",
      "  MOL: ['Styrene monomer', 'styrene residues', 'catalyst', 'hydrophobic residue', 'polystyrene', 'styrene monomer', 'HST', 'styrene monomer', 'TST', 'styrene monomer', 'styrene residue', 'styrene residue', 'SCL', 'SDB', 'catalyst', 'hydrophobic residue', 'catalyst', 'hydrophobic residue', 'TIP3P waters', 'NVT', 'NPT', 'NPT', 'NVT', 'catalyst', 'hydrophobic residues', 'styrene residues', 'SPA residues']\n",
      "  SOFTNAME: ['RESP', 'prepgen module', 'RESP', 'Particle-Mesh Ewald (PME)', 'Langevin thermostat', 'SHAKE algorithm', 'PMEMD program', 'cpptraj module', 'k-means algorithm', 'LEaP module']\n",
      "  SOFTVERS: []\n",
      "  STIME: ['1 ns', '1 ns', '2.1 ns']\n",
      "  TEMP: []\n",
      "  FFM: ['General Amber Force Field (GAFF)']\n",
      "\n",
      "★ False negatives (missed ?):\n",
      "  MOL: ['Enzyme', 'Polystyrene', 'methyl', 'Styrene', '2-phenylpropane', 'methyl', 'methyl', 'methyl', 'methyl', 'alkyl', 'p-divinylbenzene', 'p-divinylbenzene', 'waters']\n",
      "  SOFTNAME: ['SHAKE', 'PMEMD', 'LEaP']\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: []\n",
      "  FFM: ['General Amber Force Field', 'TIP3P']\n",
      "\n",
      "★ Detection ratio per type (# of correct entities found by LLM ÷ # of entities in the ground truth):\n",
      "  MOL: 0.5806451612903226\n",
      "  SOFTNAME: 0.7\n",
      "  SOFTVERS: None\n",
      "  STIME: 1.0\n",
      "  TEMP: 1.0\n",
      "  FFM: 0.5\n",
      "\n",
      "★ Per-type breakdown:\n",
      "  TEMP: {'exact_matches': 4, 'total_gt': 4, 'detection_ratio': 1.0, 'false_positives': 0, 'false_negatives': 0}\n",
      "  MOL: {'exact_matches': 18, 'total_gt': 31, 'detection_ratio': 0.5806451612903226, 'false_positives': 27, 'false_negatives': 13}\n",
      "  FFM: {'exact_matches': 2, 'total_gt': 4, 'detection_ratio': 0.5, 'false_positives': 1, 'false_negatives': 2}\n",
      "  SOFTNAME: {'exact_matches': 7, 'total_gt': 10, 'detection_ratio': 0.7, 'false_positives': 10, 'false_negatives': 3}\n",
      "  STIME: {'exact_matches': 1, 'total_gt': 1, 'detection_ratio': 1.0, 'false_positives': 3, 'false_negatives': 0}\n",
      "  SOFTVERS: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "\n",
      "../llm_outputs/annotations_2025-04-28_15-06-21/one_shot/meta-llama/llama-4-maverick-17b-128e-instruct/figshare_21263177.json \n",
      "\n",
      "★ Exact match score: 8/11 (0.73)\n",
      "\n",
      "★ False positives (hallucination ?):\n",
      "  MOL: ['proteins', 'proteins', 'E. coli thioredoxins', 'proteins', 'thioredoxin', 'proteins', 'membrane proteins', 'lipid bilayers', 'nucleic acids']\n",
      "  SOFTNAME: []\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: []\n",
      "  FFM: ['GROMOS54A7']\n",
      "\n",
      "★ False negatives (missed ?):\n",
      "  MOL: ['human and E. coli thioredoxins', 'human thioredoxin']\n",
      "  SOFTNAME: []\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: []\n",
      "  FFM: ['GROMOS 54A7']\n",
      "\n",
      "★ Detection ratio per type (# of correct entities found by LLM ÷ # of entities in the ground truth):\n",
      "  MOL: 0.6\n",
      "  SOFTNAME: 1.0\n",
      "  SOFTVERS: None\n",
      "  STIME: None\n",
      "  TEMP: None\n",
      "  FFM: 0.8\n",
      "\n",
      "★ Per-type breakdown:\n",
      "  TEMP: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  MOL: {'exact_matches': 3, 'total_gt': 5, 'detection_ratio': 0.6, 'false_positives': 9, 'false_negatives': 2}\n",
      "  FFM: {'exact_matches': 4, 'total_gt': 5, 'detection_ratio': 0.8, 'false_positives': 1, 'false_negatives': 1}\n",
      "  SOFTNAME: {'exact_matches': 1, 'total_gt': 1, 'detection_ratio': 1.0, 'false_positives': 0, 'false_negatives': 0}\n",
      "  STIME: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  SOFTVERS: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "\n",
      "../llm_outputs/annotations_2025-04-28_15-06-21/one_shot/meta-llama/llama-4-maverick-17b-128e-instruct/zenodo_6582985.json \n",
      "\n",
      "★ Exact match score: 10/13 (0.77)\n",
      "\n",
      "★ False positives (hallucination ?):\n",
      "  MOL: ['lipids']\n",
      "  SOFTNAME: ['Desmond', 'Desmond', 'Desmond']\n",
      "  SOFTVERS: ['2019-4', '2019-4']\n",
      "  STIME: ['500ns', '500ns', '500ns']\n",
      "  TEMP: []\n",
      "  FFM: []\n",
      "\n",
      "★ False negatives (missed ?):\n",
      "  MOL: []\n",
      "  SOFTNAME: ['Desmond 2019-4', 'desmond', 'desmond']\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: []\n",
      "  FFM: []\n",
      "\n",
      "★ Detection ratio per type (# of correct entities found by LLM ÷ # of entities in the ground truth):\n",
      "  MOL: 1.0\n",
      "  SOFTNAME: 0.25\n",
      "  SOFTVERS: None\n",
      "  STIME: 1.0\n",
      "  TEMP: None\n",
      "  FFM: 1.0\n",
      "\n",
      "★ Per-type breakdown:\n",
      "  TEMP: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  MOL: {'exact_matches': 6, 'total_gt': 6, 'detection_ratio': 1.0, 'false_positives': 1, 'false_negatives': 0}\n",
      "  FFM: {'exact_matches': 2, 'total_gt': 2, 'detection_ratio': 1.0, 'false_positives': 0, 'false_negatives': 0}\n",
      "  SOFTNAME: {'exact_matches': 1, 'total_gt': 4, 'detection_ratio': 0.25, 'false_positives': 3, 'false_negatives': 3}\n",
      "  STIME: {'exact_matches': 1, 'total_gt': 1, 'detection_ratio': 1.0, 'false_positives': 3, 'false_negatives': 0}\n",
      "  SOFTVERS: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 2, 'false_negatives': 0}\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "\n",
      "../llm_outputs/annotations_2025-04-28_15-06-21/one_shot/meta-llama/llama-4-maverick-17b-128e-instruct/zenodo_6478270.json \n",
      "\n",
      "★ Exact match score: 3/9 (0.33)\n",
      "\n",
      "★ False positives (hallucination ?):\n",
      "  MOL: ['LNX2 protein', 'protein chains']\n",
      "  SOFTNAME: []\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: []\n",
      "  FFM: ['CHARMM-modified TIP3P']\n",
      "\n",
      "★ False negatives (missed ?):\n",
      "  MOL: ['LNX2', 'Water', 'water', 'water']\n",
      "  SOFTNAME: []\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: []\n",
      "  FFM: ['CHARMM', 'TIP3P']\n",
      "\n",
      "★ Detection ratio per type (# of correct entities found by LLM ÷ # of entities in the ground truth):\n",
      "  MOL: 0.2\n",
      "  SOFTNAME: None\n",
      "  SOFTVERS: None\n",
      "  STIME: 1.0\n",
      "  TEMP: None\n",
      "  FFM: 0.3333333333333333\n",
      "\n",
      "★ Per-type breakdown:\n",
      "  TEMP: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  MOL: {'exact_matches': 1, 'total_gt': 5, 'detection_ratio': 0.2, 'false_positives': 2, 'false_negatives': 4}\n",
      "  FFM: {'exact_matches': 1, 'total_gt': 3, 'detection_ratio': 0.3333333333333333, 'false_positives': 1, 'false_negatives': 2}\n",
      "  SOFTNAME: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  STIME: {'exact_matches': 1, 'total_gt': 1, 'detection_ratio': 1.0, 'false_positives': 0, 'false_negatives': 0}\n",
      "  SOFTVERS: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "\n",
      "../llm_outputs/annotations_2025-04-28_15-06-21/few_shot/meta-llama/llama-4-maverick-17b-128e-instruct/figshare_22213635.json \n",
      "\n",
      "★ Exact match score: 10/10 (1.00)\n",
      "\n",
      "★ False positives (hallucination ?):\n",
      "  MOL: []\n",
      "  SOFTNAME: []\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: []\n",
      "  FFM: []\n",
      "\n",
      "★ False negatives (missed ?):\n",
      "  MOL: []\n",
      "  SOFTNAME: []\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: []\n",
      "  FFM: []\n",
      "\n",
      "★ Detection ratio per type (# of correct entities found by LLM ÷ # of entities in the ground truth):\n",
      "  MOL: 1.0\n",
      "  SOFTNAME: None\n",
      "  SOFTVERS: None\n",
      "  STIME: None\n",
      "  TEMP: 1.0\n",
      "  FFM: None\n",
      "\n",
      "★ Per-type breakdown:\n",
      "  TEMP: {'exact_matches': 1, 'total_gt': 1, 'detection_ratio': 1.0, 'false_positives': 0, 'false_negatives': 0}\n",
      "  MOL: {'exact_matches': 9, 'total_gt': 9, 'detection_ratio': 1.0, 'false_positives': 0, 'false_negatives': 0}\n",
      "  FFM: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  SOFTNAME: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  STIME: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  SOFTVERS: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "\n",
      "../llm_outputs/annotations_2025-04-28_15-06-21/few_shot/meta-llama/llama-4-maverick-17b-128e-instruct/figshare_4757161.json \n",
      "\n",
      "★ Exact match score: 29/50 (0.58)\n",
      "\n",
      "★ False positives (hallucination ?):\n",
      "  MOL: ['styrene (STY)', 'catalyst (CAT)', 'Styrene monomer', 'catalyst', 'polystyrene', 'STY: styrene monomer', 'HST: terminal (head) styrene monomer', 'TST: terminal (tail) styrene monomer', 'CAT: styrene residue with catalytic moiety attached', 'SPA: styrene residue with C16 alkyl chain attached', 'SCL: cross-linking residue (p-divinylbenzene)', 'SDB: cross-linking residue (p-divinylbenzene)', 'catalyst', 'hydrophobic residue', 'catalyst', 'hydrophobic residue', 'TIP3P waters', 'catalyst', 'hydrophobic residues']\n",
      "  SOFTNAME: ['RESP', 'prepgen', 'RESP', 'Particle-Mesh Ewald (PME)', 'Langevin thermostat', 'cpptraj']\n",
      "  SOFTVERS: []\n",
      "  STIME: ['1 ns', '1 ns', '2.1 ns']\n",
      "  TEMP: []\n",
      "  FFM: ['General Amber Force Field (GAFF)']\n",
      "\n",
      "★ False negatives (missed ?):\n",
      "  MOL: ['Enzyme', 'STY', 'CAT', 'methyl', 'Styrene', '2-phenylpropane', 'methyl', 'methyl', 'STY', 'methyl', 'methyl', 'CAT', 'alkyl', 'p-divinylbenzene', 'p-divinylbenzene', 'waters', 'CAT']\n",
      "  SOFTNAME: ['LEaP', 'Amber']\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: []\n",
      "  FFM: ['General Amber Force Field', 'TIP3P']\n",
      "\n",
      "★ Detection ratio per type (# of correct entities found by LLM ÷ # of entities in the ground truth):\n",
      "  MOL: 0.45161290322580644\n",
      "  SOFTNAME: 0.8\n",
      "  SOFTVERS: None\n",
      "  STIME: 1.0\n",
      "  TEMP: 1.0\n",
      "  FFM: 0.5\n",
      "\n",
      "★ Per-type breakdown:\n",
      "  TEMP: {'exact_matches': 4, 'total_gt': 4, 'detection_ratio': 1.0, 'false_positives': 0, 'false_negatives': 0}\n",
      "  MOL: {'exact_matches': 14, 'total_gt': 31, 'detection_ratio': 0.45161290322580644, 'false_positives': 19, 'false_negatives': 17}\n",
      "  FFM: {'exact_matches': 2, 'total_gt': 4, 'detection_ratio': 0.5, 'false_positives': 1, 'false_negatives': 2}\n",
      "  SOFTNAME: {'exact_matches': 8, 'total_gt': 10, 'detection_ratio': 0.8, 'false_positives': 6, 'false_negatives': 2}\n",
      "  STIME: {'exact_matches': 1, 'total_gt': 1, 'detection_ratio': 1.0, 'false_positives': 3, 'false_negatives': 0}\n",
      "  SOFTVERS: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "\n",
      "../llm_outputs/annotations_2025-04-28_15-06-21/few_shot/meta-llama/llama-4-maverick-17b-128e-instruct/figshare_21263177.json \n",
      "\n",
      "★ Exact match score: 8/11 (0.73)\n",
      "\n",
      "★ False positives (hallucination ?):\n",
      "  MOL: ['E. coli thioredoxins', 'proteins', 'residues']\n",
      "  SOFTNAME: ['CpHMD']\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: []\n",
      "  FFM: ['GROMOS54A7']\n",
      "\n",
      "★ False negatives (missed ?):\n",
      "  MOL: ['human and E. coli thioredoxins', 'human thioredoxin']\n",
      "  SOFTNAME: []\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: []\n",
      "  FFM: ['GROMOS 54A7']\n",
      "\n",
      "★ Detection ratio per type (# of correct entities found by LLM ÷ # of entities in the ground truth):\n",
      "  MOL: 0.6\n",
      "  SOFTNAME: 1.0\n",
      "  SOFTVERS: None\n",
      "  STIME: None\n",
      "  TEMP: None\n",
      "  FFM: 0.8\n",
      "\n",
      "★ Per-type breakdown:\n",
      "  TEMP: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  MOL: {'exact_matches': 3, 'total_gt': 5, 'detection_ratio': 0.6, 'false_positives': 3, 'false_negatives': 2}\n",
      "  FFM: {'exact_matches': 4, 'total_gt': 5, 'detection_ratio': 0.8, 'false_positives': 1, 'false_negatives': 1}\n",
      "  SOFTNAME: {'exact_matches': 1, 'total_gt': 1, 'detection_ratio': 1.0, 'false_positives': 1, 'false_negatives': 0}\n",
      "  STIME: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  SOFTVERS: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "\n",
      "../llm_outputs/annotations_2025-04-28_15-06-21/few_shot/meta-llama/llama-4-maverick-17b-128e-instruct/zenodo_6582985.json \n",
      "\n",
      "★ Exact match score: 9/13 (0.69)\n",
      "\n",
      "★ False positives (hallucination ?):\n",
      "  MOL: []\n",
      "  SOFTNAME: ['Desmond', 'Desmond', 'Desmond']\n",
      "  SOFTVERS: ['2019-4', '2019-4']\n",
      "  STIME: ['0-500ns', '500ns', '500ns']\n",
      "  TEMP: []\n",
      "  FFM: []\n",
      "\n",
      "★ False negatives (missed ?):\n",
      "  MOL: ['1-palmitoyl-2-oleoyl-phosphatidylcholine']\n",
      "  SOFTNAME: ['Desmond 2019-4', 'desmond', 'desmond']\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: []\n",
      "  FFM: []\n",
      "\n",
      "★ Detection ratio per type (# of correct entities found by LLM ÷ # of entities in the ground truth):\n",
      "  MOL: 0.8333333333333334\n",
      "  SOFTNAME: 0.25\n",
      "  SOFTVERS: None\n",
      "  STIME: 1.0\n",
      "  TEMP: None\n",
      "  FFM: 1.0\n",
      "\n",
      "★ Per-type breakdown:\n",
      "  TEMP: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  MOL: {'exact_matches': 5, 'total_gt': 6, 'detection_ratio': 0.8333333333333334, 'false_positives': 0, 'false_negatives': 1}\n",
      "  FFM: {'exact_matches': 2, 'total_gt': 2, 'detection_ratio': 1.0, 'false_positives': 0, 'false_negatives': 0}\n",
      "  SOFTNAME: {'exact_matches': 1, 'total_gt': 4, 'detection_ratio': 0.25, 'false_positives': 3, 'false_negatives': 3}\n",
      "  STIME: {'exact_matches': 1, 'total_gt': 1, 'detection_ratio': 1.0, 'false_positives': 3, 'false_negatives': 0}\n",
      "  SOFTVERS: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 2, 'false_negatives': 0}\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "\n",
      "../llm_outputs/annotations_2025-04-28_15-06-21/few_shot/meta-llama/llama-4-maverick-17b-128e-instruct/zenodo_6478270.json \n",
      "\n",
      "★ Exact match score: 2/9 (0.22)\n",
      "\n",
      "★ False positives (hallucination ?):\n",
      "  MOL: ['LNX2 protein', 'LNX2 protein', 'PDB ID:5E11', '4 symmetrically related protein chains']\n",
      "  SOFTNAME: []\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: []\n",
      "  FFM: ['CHARMM-modified TIP3P']\n",
      "\n",
      "★ False negatives (missed ?):\n",
      "  MOL: ['LNX2', 'Water', 'water', '5E11', 'water']\n",
      "  SOFTNAME: []\n",
      "  SOFTVERS: []\n",
      "  STIME: []\n",
      "  TEMP: []\n",
      "  FFM: ['CHARMM', 'TIP3P']\n",
      "\n",
      "★ Detection ratio per type (# of correct entities found by LLM ÷ # of entities in the ground truth):\n",
      "  MOL: 0.0\n",
      "  SOFTNAME: None\n",
      "  SOFTVERS: None\n",
      "  STIME: 1.0\n",
      "  TEMP: None\n",
      "  FFM: 0.3333333333333333\n",
      "\n",
      "★ Per-type breakdown:\n",
      "  TEMP: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  MOL: {'exact_matches': 0, 'total_gt': 5, 'detection_ratio': 0.0, 'false_positives': 4, 'false_negatives': 5}\n",
      "  FFM: {'exact_matches': 1, 'total_gt': 3, 'detection_ratio': 0.3333333333333333, 'false_positives': 1, 'false_negatives': 2}\n",
      "  SOFTNAME: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "  STIME: {'exact_matches': 1, 'total_gt': 1, 'detection_ratio': 1.0, 'false_positives': 0, 'false_negatives': 0}\n",
      "  SOFTVERS: {'exact_matches': 0, 'total_gt': 0, 'detection_ratio': None, 'false_positives': 0, 'false_negatives': 0}\n",
      "\n",
      " ======================================================================================================================================================================================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if scoring file already exists. If it does, delete it.\n",
    "summary_file_path = Path(SCORE_RESULTS_PATH)\n",
    "if summary_file_path.exists():\n",
    "    os.remove(summary_file_path)\n",
    "    print(f\"Overwriting existing file: {summary_file_path}\\n\\n\")\n",
    "\n",
    "# Loop through the filenames and process each one\n",
    "for i in range(len(llm_filenames)):\n",
    "    llm_filename = llm_filenames[i]\n",
    "    gt_filename = filenames[i]\n",
    "\n",
    "    # Collect rows in memory\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "\n",
    "    # Process the ground-truth JSON file and extract entities\n",
    "    input_text, ground_truth_entities = process_json_file(gt_filename)\n",
    "    gt_extracted = extract_entities_from_annotation(input_text, ground_truth_entities)\n",
    "    # print(\"Ground-truth entities:\", gt_extracted)\n",
    "\n",
    "    # Process the LLM JSON file and extract entities\n",
    "    _, response, _ = process_llm_json_file(llm_filename)\n",
    "    llm_extracted = extract_entities_from_llm_text(response)\n",
    "    # print(\"LLM extracted entities:\", llm_extracted)\n",
    "    \n",
    "\n",
    "    # Calculate the exact match score ========================================\n",
    "    matched, total, score_ratio = exact_match_score(gt_extracted, llm_extracted)\n",
    "    \n",
    "    # False positives ========================================================\n",
    "    fps = false_positives(gt_extracted, llm_extracted)\n",
    "    joined_false_positives: dict[str, str] = {}\n",
    "    \n",
    "    # False negatives ========================================================\n",
    "    fns = false_negatives(gt_extracted, llm_extracted)\n",
    "    joined_false_negatives: dict[str, str] = {}\n",
    "    \n",
    "    # Calculate the detection ratio ==========================================\n",
    "    detect_ratio = detection_ratio(gt_extracted, llm_extracted)\n",
    "\n",
    "    # Per-type breakdown =====================================================\n",
    "    breakdown = per_type_breakdown(gt_extracted, llm_extracted)\n",
    "    stats_breakdown: dict[str, int] = {}\n",
    "\n",
    "\n",
    "    # Print results ==========================================================\n",
    "    print(llm_filename, \"\\n\")\n",
    "    print(f\"★ Exact match score: {matched}/{total} ({score_ratio:.2f})\")\n",
    "\n",
    "    print(\"\\n★ False positives (hallucination ?):\")\n",
    "    for etype, fp_list in fps.items():\n",
    "        print(f\"  {etype}: {fp_list}\")\n",
    "\n",
    "        joined_fp = \"; \".join(map(str, fp_list))\n",
    "        joined_false_positives[etype] = joined_fp\n",
    "\n",
    "    print(\"\\n★ False negatives (missed ?):\")\n",
    "    for etype, fn_list in fns.items():\n",
    "        print(f\"  {etype}: {fn_list}\")\n",
    "        \n",
    "        joined_fn = \"; \".join(map(str, fn_list))\n",
    "        joined_false_negatives[etype] = joined_fn\n",
    "\n",
    "    print(\"\\n★ Detection ratio per type (# of correct entities found by LLM ÷ # of entities in the ground truth):\")\n",
    "    for etype, ratio in detect_ratio.items():\n",
    "        print(f\"  {etype}: {ratio}\")\n",
    "\n",
    "    print(\"\\n★ Per-type breakdown:\")\n",
    "    for etype, stats in breakdown.items():\n",
    "        print(f\"  {etype}: {stats}\")\n",
    "\n",
    "        stats_breakdown[f\"{etype}_correct\"] = stats[\"exact_matches\"]\n",
    "        stats_breakdown[f\"{etype}_total\"] = stats[\"total_gt\"]\n",
    "\n",
    "    \n",
    "    print(\"\\n\",\"=\"*200, \"\\n\")\n",
    "\n",
    "    # Save the results to a CSV file -----------------------------------\n",
    "\n",
    "    # Prompt = 0\n",
    "    # Model = 1\n",
    "    # Filename = 2\n",
    "    # Full path = 3\n",
    "\n",
    "    prompt_name = df.iloc[i, 0]\n",
    "    model = df.iloc[i, 1]\n",
    "    filename = df.iloc[i, 2]\n",
    "    file_path = df.iloc[i, 3]\n",
    "\n",
    "    percentage_correct = round(score_ratio * 100, 2)\n",
    "\n",
    "    rows.append(\n",
    "        {\n",
    "            \"prompt\": prompt_name,\n",
    "            \"model\": model,\n",
    "            \"filename\": filename,\n",
    "            \"percentage_correct\": percentage_correct,\n",
    "            \"total_correct\": matched,\n",
    "            \"total\": total,\n",
    "            \"MOL_correct\":stats_breakdown[\"MOL_correct\"],\n",
    "            \"MOL_total\":stats_breakdown[\"MOL_total\"],\n",
    "            \"MOL_FP\":joined_false_positives[\"MOL\"],\n",
    "            \"MOL_FN\":joined_false_negatives[\"MOL\"],\n",
    "            \"SOFTNAME_correct\":stats_breakdown[\"SOFTNAME_correct\"],\n",
    "            \"SOFTNAME_total\":stats_breakdown[\"SOFTNAME_total\"],\n",
    "            \"SOFTNAME_FP\":joined_false_positives[\"SOFTNAME\"],\n",
    "            \"SOFTNAME_FN\":joined_false_negatives[\"SOFTNAME\"],\n",
    "            \"SOFTVERS_correct\":stats_breakdown[\"SOFTVERS_correct\"],\n",
    "            \"SOFTVERS_total\":stats_breakdown[\"SOFTVERS_total\"],\n",
    "            \"SOFTVERS_FP\":joined_false_positives[\"SOFTVERS\"],\n",
    "            \"SOFTVERS_FN\":joined_false_negatives[\"SOFTVERS\"],\n",
    "            \"STIME_correct\":stats_breakdown[\"STIME_correct\"],\n",
    "            \"STIME_total\":stats_breakdown[\"STIME_total\"],\n",
    "            \"STIME_FP\":joined_false_positives[\"STIME\"],\n",
    "            \"STIME_FN\":joined_false_negatives[\"STIME\"],\n",
    "            \"TEMP_correct\":stats_breakdown[\"TEMP_correct\"],\n",
    "            \"TEMP_total\":stats_breakdown[\"TEMP_total\"],\n",
    "            \"TEMP_FP\":joined_false_positives[\"TEMP\"],\n",
    "            \"TEMP_FN\":joined_false_negatives[\"TEMP\"],\n",
    "            \"FFM_correct\":stats_breakdown[\"FFM_correct\"],\n",
    "            \"FFM_total\":stats_breakdown[\"FFM_total\"],\n",
    "            \"FFM_FP\":joined_false_positives[\"FFM\"],\n",
    "            \"FFM_FN\":joined_false_negatives[\"FFM\"],\n",
    "            \"full path\": str(file_path),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    output_path = SCORE_RESULTS_FOLDER\n",
    "    save_scoring_results_to_csv(rows, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
